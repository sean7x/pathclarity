{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load and concatenate all the CSV files\n",
    "The empty columns will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files from `../data/interim` into a list of DataFrames\n",
    "# Add a new column to each DataFrame with the name of the file\n",
    "csv_path = os.path.join('..', 'data', 'interim')\n",
    "dfs = []\n",
    "\n",
    "for f in sorted(os.listdir(csv_path)):\n",
    "    if f.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(csv_path, f))\n",
    "        df['file'] = f\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35105, 408)\n",
      "(34473, 413)\n",
      "(33908, 413)\n",
      "(33551, 404)\n",
      "(34718, 429)\n",
      "(32233, 447)\n",
      "\n",
      "['BIOTER', 'ULTRASND', 'NOTOBAC', 'MDSP', 'PREGNANT', 'RACE', 'GESTWK', 'ETHNIC']\n",
      "['BIOTER', 'ULTRASND', 'PAYTYPE', 'NOTOBAC', 'MDSP', 'PREGNANT', 'RACE', 'GESTWK', 'ETHNIC']\n",
      "['OTHPR12D', 'BIOTER', 'RETPRN', 'RACEFL', 'OTHPROC3', 'SCOPWI1R', 'SCOPPROC', 'OTHPR22D', 'DIAGSC2', 'OTHPR13D', 'MDSP', 'CASTAGE', 'SCOPWI2R', 'DIAGSC1', 'RACE', 'NOFU', 'DIAGSC1R', 'DIGSC23D', 'ULTRASND', 'DIGSC22D', 'PAYTYPE', 'SCOPEWI2', 'HOSPICE', 'OTHPROC2R', 'RADTHER', 'OTHPROC3R', 'OTHPROC4', 'SCOPEWI1', 'OTHPROC1', 'DIGSC13D', 'SPIRO', 'OTHPR33D', 'DIAGSC2R', 'OTHPROC4R', 'OTHPROC2', 'OTHPROC', 'SCPWI22D', 'SCPWI13D', 'BLANK', 'RACEETH', 'ORTHO', 'OTHPR23D', 'DIGSC12D', 'SCPWI12D', 'REFERED', 'GESTWK', 'OTHPROC1R', 'TOTDIAG', 'ETHNIC', 'OTHPR32D', 'ELECTROL', 'SCPWI23D', 'TELEPHON', 'OTHDIAG', 'ADMITHOS', 'DMP', 'OTHPR43D', 'NOTOBAC', 'TOTNONMED', 'NONMED', 'OTHPR42D', 'PREGNANT', 'DIAGSCRN']\n",
      "['OTHPR12D', 'BIOTER', 'EPUBHTHO', 'RETPRN', 'RACEFL', 'OTHPROC3', 'SCOPWI1R', 'SCOPPROC', 'OTHPR22D', 'DIAGSC2', 'OTHPR13D', 'MDSP', 'VYEAR', 'EIMAGEO', 'SCOPWI2R', 'DIAGSC1', 'RACE', 'NOFU', 'DIAGSC1R', 'EMRNEWO', 'DIGSC23D', 'ULTRASND', 'DIGSC22D', 'ENOTDISO', 'SCOPEWI2', 'PAYTYPE', 'HOSPICE', 'OTHPROC2R', 'OTHPROC3R', 'OTHPROC4', 'SCOPEWI1', 'OTHPROC1', 'DIGSC13D', 'SPIRO', 'OTHPR33D', 'DIAGSC2R', 'OTHPROC4R', 'OTHPROC2', 'OTHPROC', 'SCPWI22D', 'SCPWI13D', 'BLANK', 'RACEETH', 'ORTHO', 'OTHPR23D', 'DIGSC12D', 'SCPWI12D', 'REFERED', 'GESTWK', 'OTHPROC1R', 'TOTDIAG', 'ETHNIC', 'OTHPR32D', 'EHXFUO', 'ELECTROL', 'SCPWI23D', 'TELEPHON', 'OTHDIAG', 'ADMITHOS', 'DMP', 'OTHPR43D', 'NOTOBAC', 'TOTNONMED', 'NONMED', 'OTHPR42D', 'PREGNANT', 'DIAGSCRN']\n",
      "['OTHPR12D', 'BIOTER', 'EPUBHTHO', 'RETPRN', 'RACEFL', 'OTHPROC3', 'SCOPWI1R', 'SCOPPROC', 'OTHPR22D', 'DIAGSC2', 'OTHPR13D', 'MDSP', 'VYEAR', 'EIMAGEO', 'CASTAGE', 'SCOPWI2R', 'DIAGSC1', 'PAPCONV', 'NOFU', 'DIAGSC1R', 'RACE', 'EMRNEWO', 'DIGSC23D', 'ULTRASND', 'DIGSC22D', 'PAYTYPE', 'SCOPEWI2', 'HOSPICE', 'OTHPROC2R', 'OTHPROC3R', 'OTHPROC4', 'SCOPEWI1', 'URBANRUR', 'OTHPROC1', 'DIGSC13D', 'SPIRO', 'OTHPR33D', 'HINCOMER', 'PAPUNSP', 'DIAGSC2R', 'OTHPROC4R', 'ERANGEO', 'OTHPROC2', 'OTHPROC', 'SCPWI22D', 'SCPWI13D', 'BLANK', 'RACEETH', 'ORTHO', 'PAPLIQ', 'OTHPR23D', 'DIGSC12D', 'SCPWI12D', 'REFERED', 'GESTWK', 'OTHPROC1R', 'PCTPOVR', 'TOTDIAG', 'ETHNIC', 'OTHPR32D', 'EHXFUO', 'ELECTROL', 'SCPWI23D', 'TELEPHON', 'OTHDIAG', 'CCS', 'PBAMORER', 'ADMITHOS', 'DMP', 'OTHPR43D', 'NOTOBAC', 'TOTNONMED', 'NONMED', 'OTHPR42D', 'PREGNANT', 'DIAGSCRN']\n"
     ]
    }
   ],
   "source": [
    "# Check the dimension of each DataFrame\n",
    "dims = [df.shape for df in dfs]\n",
    "\n",
    "for i in range(len(dims)):\n",
    "    print(dims[i])\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Check the columns of each DataFrame and check the differences\n",
    "columns = [df.columns for df in dfs]\n",
    "diffs = [list(set(columns[0]) - set(col)) for col in columns[1:]]\n",
    "\n",
    "for i in range(len(diffs)):\n",
    "    print(diffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the concatenated DataFrame is:\n",
      "(203988, 544)\n",
      "\n",
      "The shape of the DataFrame after dropping columns with all NaN values is:\n",
      "(203988, 532)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print('The shape of the concatenated DataFrame is:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "# Drop the columns with all NaN values\n",
    "print('The shape of the DataFrame after dropping columns with all NaN values is:')\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Check the distribution of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file      opd2006.csv  opd2007.csv  opd2008.csv  opd2009.csv  opd2010.csv  \\\n",
      "COMSTAT8        33241        31864        31054        30433        31182   \n",
      "CONTSUB8        33241        31864        31054        30433        31182   \n",
      "PRESCR8         33241        31864        31054        30433        31182   \n",
      "COMSTAT7        32465        30844        30050        29361        30000   \n",
      "CONTSUB7        32465        30844        30050        29361        30000   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "PAPUNSP             0            0            0            0            0   \n",
      "URBANRUR            0            0            0            0            0   \n",
      "CCS                 0            0            0            0            0   \n",
      "PAPCONV             0            0            0            0            0   \n",
      "PASTVIS          1664            0            0            0            0   \n",
      "\n",
      "file      opd2011.csv     sum  \n",
      "COMSTAT8        28841  186615  \n",
      "CONTSUB8        28841  186615  \n",
      "PRESCR8         28841  186615  \n",
      "COMSTAT7        27777  180497  \n",
      "CONTSUB7        27777  180497  \n",
      "...               ...     ...  \n",
      "PAPUNSP         32233   32233  \n",
      "URBANRUR        32233   32233  \n",
      "CCS             32233   32233  \n",
      "PAPCONV         32233   32233  \n",
      "PASTVIS             0    1664  \n",
      "\n",
      "[228 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by the `file` column and count the number of NaN values in each group\n",
    "# Drop the columns with zero NaN values\n",
    "# Transpose the resulting DataFrame and add a sum column\n",
    "# Sort the DataFrame by the sum column\n",
    "nan_counts = df.groupby('file').apply(lambda x: x.isna().sum(), include_groups=False)\n",
    "nan_counts = nan_counts.loc[:, (nan_counts != 0).any(axis=0)]\n",
    "nan_counts = nan_counts.T\n",
    "nan_counts['sum'] = nan_counts.sum(axis=1)\n",
    "nan_counts = nan_counts.sort_values(by='sum', ascending=False)\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file      opd2006.csv  opd2007.csv  opd2008.csv  opd2009.csv  opd2010.csv  \\\n",
      "COMSTAT8     0.946902     0.924318     0.915831     0.907067     0.898151   \n",
      "CONTSUB8     0.946902     0.924318     0.915831     0.907067     0.898151   \n",
      "PRESCR8      0.946902     0.924318     0.915831     0.907067     0.898151   \n",
      "CONTSUB7     0.924797     0.894729     0.886222     0.875115     0.864105   \n",
      "COMSTAT7     0.924797     0.894729     0.886222     0.875115     0.864105   \n",
      "...               ...          ...          ...          ...          ...   \n",
      "PREGTEST     1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "MHP          1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "PAPCONV      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "OPDWT        0.993306     0.000000     0.000000     0.000000     0.000000   \n",
      "PASTVIS      0.047401     0.000000     0.000000     0.000000     0.000000   \n",
      "\n",
      "file      opd2011.csv       sum  \n",
      "COMSTAT8     0.894766  0.914506  \n",
      "CONTSUB8     0.894766  0.914506  \n",
      "PRESCR8      0.894766  0.914506  \n",
      "CONTSUB7     0.861757  0.884454  \n",
      "COMSTAT7     0.861757  0.884454  \n",
      "...               ...       ...  \n",
      "PREGTEST     0.000000  0.166667  \n",
      "MHP          0.000000  0.166667  \n",
      "PAPCONV      1.000000  0.166667  \n",
      "OPDWT        0.000000  0.165551  \n",
      "PASTVIS      0.000000  0.007900  \n",
      "\n",
      "[228 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the percentage of NaN values in each column in each group\n",
    "nan_perc = df.groupby('file').apply(lambda x: x.isna().mean(), include_groups=False)\n",
    "nan_perc = nan_perc.loc[:, (nan_perc != 0).any(axis=0)]\n",
    "nan_perc = nan_perc.T\n",
    "nan_perc['sum'] = nan_perc.sum(axis=1) / len(dfs)\n",
    "nan_perc = nan_perc.sort_values(by='sum', ascending=False)\n",
    "print(nan_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file       opd2006.csv  opd2007.csv  opd2008.csv  opd2009.csv  opd2010.csv  \\\n",
      "BLANK2             1.0          1.0          1.0          1.0          0.0   \n",
      "PAP                1.0          1.0          1.0          1.0          1.0   \n",
      "EBILLANYO          1.0          1.0          1.0          1.0          1.0   \n",
      "EMEDALGO           1.0          1.0          1.0          1.0          1.0   \n",
      "ESETSO             1.0          1.0          1.0          1.0          1.0   \n",
      "\n",
      "file       opd2011.csv  counts_of_files  \n",
      "BLANK2             1.0              5.0  \n",
      "PAP                0.0              5.0  \n",
      "EBILLANYO          0.0              5.0  \n",
      "EMEDALGO           0.0              5.0  \n",
      "ESETSO             0.0              5.0  \n",
      "\n",
      "The number of columns that have all NaN values in some file is:\n",
      "202\n",
      "\n",
      "file       opd2006.csv  opd2007.csv  opd2008.csv  opd2009.csv  opd2010.csv  \\\n",
      "BLANK2             1.0          1.0          1.0          1.0          0.0   \n",
      "PAP                1.0          1.0          1.0          1.0          1.0   \n",
      "EBILLANYO          1.0          1.0          1.0          1.0          1.0   \n",
      "EMEDALGO           1.0          1.0          1.0          1.0          1.0   \n",
      "ESETSO             1.0          1.0          1.0          1.0          1.0   \n",
      "\n",
      "file       opd2011.csv  counts_of_files  \n",
      "BLANK2             1.0              5.0  \n",
      "PAP                0.0              5.0  \n",
      "EBILLANYO          0.0              5.0  \n",
      "EMEDALGO           0.0              5.0  \n",
      "ESETSO             0.0              5.0  \n",
      "\n",
      "The number of columns that more than 4 files have all NaN values is:\n",
      "60\n",
      "\n",
      "file       opd2006.csv  opd2007.csv  opd2008.csv  opd2009.csv  opd2010.csv  \\\n",
      "TOTNONMED          0.0          0.0          0.0          1.0          1.0   \n",
      "NOFU               0.0          0.0          0.0          1.0          1.0   \n",
      "OTHPR42D           0.0          0.0          0.0          1.0          1.0   \n",
      "TELEPHON           0.0          0.0          0.0          1.0          1.0   \n",
      "REFERED            0.0          0.0          0.0          1.0          1.0   \n",
      "\n",
      "file       opd2011.csv  counts_of_files  \n",
      "TOTNONMED          1.0              3.0  \n",
      "NOFU               1.0              3.0  \n",
      "OTHPR42D           1.0              3.0  \n",
      "TELEPHON           1.0              3.0  \n",
      "REFERED            1.0              3.0  \n",
      "\n",
      "The number of columns that more than 3 files have all NaN values is:\n",
      "100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the columns that have all NaN values in some file \n",
    "all_nan_cols = nan_perc.drop('sum', axis=1)[(nan_perc == 1).any(axis=1)]\n",
    "\n",
    "# Count the number of files that have all NaN values in each column\n",
    "all_nan_cols['counts_of_files'] = all_nan_cols.sum(axis=1)\n",
    "print(all_nan_cols.head(5))\n",
    "print()\n",
    "print('The number of columns that have all NaN values in some file is:')\n",
    "print(len(all_nan_cols))\n",
    "print()\n",
    "\n",
    "# Check the columns that more than 4 files have all NaN values\n",
    "more_than_4_nan_cols = all_nan_cols[all_nan_cols['counts_of_files'] > 4]\n",
    "print(more_than_4_nan_cols.head(5))\n",
    "print()\n",
    "print('The number of columns that more than 4 files have all NaN values is:')\n",
    "print(len(more_than_4_nan_cols))\n",
    "print()\n",
    "\n",
    "# Check the columns that more than 3 files have all NaN values\n",
    "more_than_3_nan_cols = all_nan_cols[all_nan_cols['counts_of_files'] == 3]\n",
    "print(more_than_3_nan_cols.head(5))\n",
    "print()\n",
    "print('The number of columns that more than 3 files have all NaN values is:')\n",
    "print(len(more_than_3_nan_cols))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the DataFrame after dropping columns with all NaN values is:\n",
      "(203988, 532)\n",
      "\n",
      "The shape of the DataFrame after dropping columns that have all NaN values in some file is:\n",
      "(203988, 330)\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns that have all NaN values in some file\n",
    "print('The shape of the DataFrame after dropping columns with all NaN values is:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "print('The shape of the DataFrame after dropping columns that have all NaN values in some file is:')\n",
    "df_wo_allnan = df.drop(all_nan_cols.index, axis=1)\n",
    "print(df_wo_allnan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VMONTH', 'VDAYR', 'AGE', 'SEX', 'USETOBAC', 'PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'INJDET', 'INJURY', 'RFV1', 'RFV2', 'RFV3', 'RFV13D', 'RFV23D', 'RFV33D', 'PRIMCARE', 'REFER', 'SENBEFOR', 'PASTVIS', 'MAJOR', 'DIAG1', 'DIAG2', 'DIAG3', 'DIAG13D', 'DIAG23D', 'DIAG33D', 'PRDIAG1', 'PRDIAG2', 'PRDIAG3', 'ARTHRTIS', 'ASTHMA', 'CANCER', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS', 'BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'ANYIMAGE', 'BONEDENS', 'MAMMO', 'MRI', 'XRAY', 'OTHIMAGE', 'CBC', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'SIGCOLON', 'BIOPSY', 'CHLAMYD', 'HPVDNA', 'EKG', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'HEALTHED', 'ASTHMAED', 'DIETNUTR', 'EXERCISE', 'GRWTHDEV', 'INJPREV', 'STRESMGT', 'TOBACED', 'WTREDUC', 'OTHLTHED', 'TOTHLTED', 'CAM', 'DME', 'HOMEHLTH', 'PT', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'WOUND', 'MED', 'MED1', 'MED2', 'MED3', 'MED4', 'MED5', 'MED6', 'MED7', 'MED8', 'NCMED1', 'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8', 'NUMNEW', 'NUMCONT', 'NUMMED', 'NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV', 'NODISP', 'REFOTHMD', 'RETAPPT', 'OTHDISP', 'PATWT', 'REGION', 'MSA', 'OWNER', 'HOSPCODE', 'CLINTYPE', 'PATCODE', 'BDATEFL', 'SEXFL', 'ETHNICFL', 'SENBEFL', 'PASTFL', 'DRUGID1', 'PRESCR1', 'CONTSUB1', 'COMSTAT1', 'RX1CAT1', 'RX1CAT2', 'RX1CAT3', 'RX1CAT4', 'RX1V1C1', 'RX1V1C2', 'RX1V1C3', 'RX1V1C4', 'RX1V2C1', 'RX1V2C2', 'RX1V2C3', 'RX1V2C4', 'RX1V3C1', 'RX1V3C2', 'RX1V3C3', 'RX1V3C4', 'DRUGID2', 'PRESCR2', 'CONTSUB2', 'COMSTAT2', 'RX2CAT1', 'RX2CAT2', 'RX2CAT3', 'RX2CAT4', 'RX2V1C1', 'RX2V1C2', 'RX2V1C3', 'RX2V1C4', 'RX2V2C1', 'RX2V2C2', 'RX2V2C3', 'RX2V2C4', 'RX2V3C1', 'RX2V3C2', 'RX2V3C3', 'RX2V3C4', 'DRUGID3', 'PRESCR3', 'CONTSUB3', 'COMSTAT3', 'RX3CAT1', 'RX3CAT2', 'RX3CAT3', 'RX3CAT4', 'RX3V1C1', 'RX3V1C2', 'RX3V1C3', 'RX3V1C4', 'RX3V2C1', 'RX3V2C2', 'RX3V2C3', 'RX3V2C4', 'RX3V3C1', 'RX3V3C2', 'RX3V3C3', 'RX3V3C4', 'DRUGID4', 'PRESCR4', 'CONTSUB4', 'COMSTAT4', 'RX4CAT1', 'RX4CAT2', 'RX4CAT3', 'RX4CAT4', 'RX4V1C1', 'RX4V1C2', 'RX4V1C3', 'RX4V1C4', 'RX4V2C1', 'RX4V2C2', 'RX4V2C3', 'RX4V2C4', 'RX4V3C1', 'RX4V3C2', 'RX4V3C3', 'RX4V3C4', 'DRUGID5', 'PRESCR5', 'CONTSUB5', 'COMSTAT5', 'RX5CAT1', 'RX5CAT2', 'RX5CAT3', 'RX5CAT4', 'RX5V1C1', 'RX5V1C2', 'RX5V1C3', 'RX5V1C4', 'RX5V2C1', 'RX5V2C2', 'RX5V2C3', 'RX5V2C4', 'RX5V3C1', 'RX5V3C2', 'RX5V3C3', 'RX5V3C4', 'DRUGID6', 'PRESCR6', 'CONTSUB6', 'COMSTAT6', 'RX6CAT1', 'RX6CAT2', 'RX6CAT3', 'RX6CAT4', 'RX6V1C1', 'RX6V1C2', 'RX6V1C3', 'RX6V1C4', 'RX6V2C1', 'RX6V2C2', 'RX6V2C3', 'RX6V2C4', 'RX6V3C1', 'RX6V3C2', 'RX6V3C3', 'RX6V3C4', 'DRUGID7', 'PRESCR7', 'CONTSUB7', 'COMSTAT7', 'RX7CAT1', 'RX7CAT2', 'RX7CAT3', 'RX7CAT4', 'RX7V1C1', 'RX7V1C2', 'RX7V1C3', 'RX7V1C4', 'RX7V2C1', 'RX7V2C2', 'RX7V2C3', 'RX7V2C4', 'RX7V3C1', 'RX7V3C2', 'RX7V3C3', 'RX7V3C4', 'DRUGID8', 'PRESCR8', 'CONTSUB8', 'COMSTAT8', 'RX8CAT1', 'RX8CAT2', 'RX8CAT3', 'RX8CAT4', 'RX8V1C1', 'RX8V1C2', 'RX8V1C3', 'RX8V1C4', 'RX8V2C1', 'RX8V2C2', 'RX8V2C3', 'RX8V2C4', 'RX8V3C1', 'RX8V3C2', 'RX8V3C3', 'RX8V3C4', 'EMROPD', 'EDEMOGO', 'ECPOEO', 'EWARNO', 'ESCRIPO', 'ECTOEO', 'EORDERO', 'ERESULTO', 'EIMGRESO', 'EPNOTESO', 'EREMINDO', 'RACER', 'AGEDAYS', 'AGER', 'DIAG1R', 'DIAG2R', 'DIAG3R', 'WHOCOMP', 'SETTYPE', 'YEAR', 'CSTRATM', 'CPSUM', 'OPDWT', 'file']\n"
     ]
    }
   ],
   "source": [
    "print(df_wo_allnan.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Feature definition and selection\n",
    "Not including \"DRUG-RELATED INFO FOR MEDICATION #1-8\" or \"DIAGNOSIS RECODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE OF VISIT\n",
    "dateOfVisit = ['VMONTH', 'VYEAR', 'VDAYR', 'YEAR']\n",
    "\n",
    "# Indepedent variables\n",
    "demographics = [\n",
    "    'AGE', 'SEX', 'PREGNANT', 'GESTWEEK', 'ETHNIC', 'RACE', 'USETOBAC', 'NOTOBAC'\n",
    "]\n",
    "payment = ['PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPE']\n",
    "visitReason = [\n",
    "    'INJDET',\n",
    "    'INJURY',\n",
    "    'MAJOR', 'RFV1', 'RFV2', 'RFV3'\n",
    "]\n",
    "patientClinicHistory = ['SENBEFOR', 'PASTVIS']\n",
    "\n",
    "# Supplementary Independent Variables\n",
    "vitalSigns = ['HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS']\n",
    "imputedFields = ['BDATEFL', 'SEXFL', 'ETHNICFL', 'RACEFL', 'SENBEFL', 'PASTFL']\n",
    "\n",
    "# Not sure if Independent or Dependent variables\n",
    "physicianDiagnoses = ['DIAG1', 'DIAG2', 'DIAG3']\n",
    "differentialDiagnoses = ['PRDIAG1', 'PRDIAG2', 'PRDIAG3']\n",
    "presentSymptomsStatus = [\n",
    "    'ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', \n",
    "    'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', \n",
    "    'HTN', 'IHD', 'OBESITY', 'OSTPRSIS',\n",
    "    'NOCHRON', 'TOTCHRON',\n",
    "    'DMP'\n",
    "]\n",
    "\n",
    "# Dependent variables\n",
    "diagnosticScreeningServices = [\n",
    "    #'DIAGSCRN', 'TOTDIAG',\n",
    "    'BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS',\n",
    "    #'ANYIMAGE',\n",
    "    'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE',\n",
    "    'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD',\n",
    "    #'SCOPPROC', 'SIGCOLON',\n",
    "    'SCOPEWI1', 'SCOPEWI2',\n",
    "    'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE',\n",
    "    'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES',\n",
    "    #'OTHDIAG',\n",
    "    'DIAGSC1', 'DIAGSC2',\n",
    "]\n",
    "healthEducation = [\n",
    "    #'HEALTHED', 'TOTHLTED',\n",
    "    'ASTHMAED', 'DIETNUTR', 'EXERCISE', 'GRWTHDEV', 'INJPREV', 'STRESMGT', 'TOBACED', 'WTREDUC', 'OTHLTHED'\n",
    "]\n",
    "nonMedicationTreatments = [\n",
    "    #'NONMED', 'TOTNONMED',\n",
    "    'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND',\n",
    "    #'OTHPROC',\n",
    "    'OTHPROC1', 'OTHPROC2', 'OTHPROC3', 'OTHPROC4'\n",
    "]\n",
    "medicationsAndImmunizations = [\n",
    "    #'MED', 'NUMMED',\n",
    "    'MED1', 'MED2', 'MED3', 'MED4', 'MED5', 'MED6', 'MED7', 'MED8',\n",
    "    'NCMED1', 'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8',\n",
    "    'NUMNEW', 'NUMCONT'\n",
    "]\n",
    "providersSeen = [\n",
    "    'NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV'\n",
    "]\n",
    "visitDisposition = [\n",
    "    'NODISP', 'NOFU', 'RETPRN', 'REFOTHMD', 'RETAPPT', 'TELEPHON', 'REFERED', 'ADMITHOS', 'OTHDISP'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure to include or not\n",
    "drugInformation1 = [\n",
    "    'DRUGID1',\n",
    "    'PRESCR1', 'CONTSUB1', 'COMSTAT1',\n",
    "    'RX1CAT1', 'RX1CAT2', 'RX1CAT3', 'RX1CAT4',\n",
    "    'RX1V1C1', 'RX1V1C2', 'RX1V1C3', 'RX1V1C4',\n",
    "    'RX1V2C1', 'RX1V2C2', 'RX1V2C3', 'RX1V2C4',\n",
    "    'RX1V3C1', 'RX1V3C2', 'RX1V3C3', 'RX1V3C4',\n",
    "]\n",
    "drugInformation2 = [\n",
    "    'DRUGID2',\n",
    "    'PRESCR2', 'CONTSUB2', 'COMSTAT2',\n",
    "    'RX2CAT1', 'RX2CAT2', 'RX2CAT3', 'RX2CAT4',\n",
    "    'RX2V1C1', 'RX2V1C2', 'RX2V1C3', 'RX2V1C4',\n",
    "    'RX2V2C1', 'RX2V2C2', 'RX2V2C3', 'RX2V2C4',\n",
    "    'RX2V3C1', 'RX2V3C2', 'RX2V3C3', 'RX2V3C4',\n",
    "]\n",
    "drugInformation3 = [\n",
    "    'DRUGID3',\n",
    "    'PRESCR3', 'CONTSUB3', 'COMSTAT3',\n",
    "    'RX3CAT1', 'RX3CAT2', 'RX3CAT3', 'RX3CAT4',\n",
    "    'RX3V1C1', 'RX3V1C2', 'RX3V1C3', 'RX3V1C4',\n",
    "    'RX3V2C1', 'RX3V2C2', 'RX3V2C3', 'RX3V2C4',\n",
    "    'RX3V3C1', 'RX3V3C2', 'RX3V3C3', 'RX3V3C4',\n",
    "]\n",
    "drugInformation4 = [\n",
    "    'DRUGID4',\n",
    "    'PRESCR4', 'CONTSUB4', 'COMSTAT4',\n",
    "    'RX4CAT1', 'RX4CAT2', 'RX4CAT3', 'RX4CAT4',\n",
    "    'RX4V1C1', 'RX4V1C2', 'RX4V1C3', 'RX4V1C4',\n",
    "    'RX4V2C1', 'RX4V2C2', 'RX4V2C3', 'RX4V2C4',\n",
    "    'RX4V3C1', 'RX4V3C2', 'RX4V3C3', 'RX4V3C4',\n",
    "]\n",
    "drugInformation5 = [\n",
    "    'DRUGID5',\n",
    "    'PRESCR5', 'CONTSUB5', 'COMSTAT5',\n",
    "    'RX5CAT1', 'RX5CAT2', 'RX5CAT3', 'RX5CAT4',\n",
    "    'RX5V1C1', 'RX5V1C2', 'RX5V1C3', 'RX5V1C4',\n",
    "    'RX5V2C1', 'RX5V2C2', 'RX5V2C3', 'RX5V2C4',\n",
    "    'RX5V3C1', 'RX5V3C2', 'RX5V3C3', 'RX5V3C4',\n",
    "]\n",
    "drugInformation6 = [\n",
    "    'DRUGID6',\n",
    "    'PRESCR6', 'CONTSUB6', 'COMSTAT6',\n",
    "    'RX6CAT1', 'RX6CAT2', 'RX6CAT3', 'RX6CAT4',\n",
    "    'RX6V1C1', 'RX6V1C2', 'RX6V1C3', 'RX6V1C4',\n",
    "    'RX6V2C1', 'RX6V2C2', 'RX6V2C3', 'RX6V2C4',\n",
    "    'RX6V3C1', 'RX6V3C2', 'RX6V3C3', 'RX6V3C4',\n",
    "]\n",
    "drugInformation7 = [\n",
    "    'DRUGID7',\n",
    "    'PRESCR7', 'CONTSUB7', 'COMSTAT7',\n",
    "    'RX7CAT1', 'RX7CAT2', 'RX7CAT3', 'RX7CAT4',\n",
    "    'RX7V1C1', 'RX7V1C2', 'RX7V1C3', 'RX7V1C4',\n",
    "    'RX7V2C1', 'RX7V2C2', 'RX7V2C3', 'RX7V2C4',\n",
    "    'RX7V3C1', 'RX7V3C2', 'RX7V3C3', 'RX7V3C4',\n",
    "]\n",
    "drugInformation8 = [\n",
    "    'DRUGID8',\n",
    "    'PRESCR8', 'CONTSUB8', 'COMSTAT8',\n",
    "    'RX8CAT1', 'RX8CAT2', 'RX8CAT3', 'RX8CAT4',\n",
    "    'RX8V1C1', 'RX8V1C2', 'RX8V1C3', 'RX8V1C4',\n",
    "    'RX8V2C1', 'RX8V2C2', 'RX8V2C3', 'RX8V2C4',\n",
    "    'RX8V3C1', 'RX8V3C2', 'RX8V3C3', 'RX8V3C4',\n",
    "]\n",
    "drugInformation = [\n",
    "    drugInformation1, drugInformation2, drugInformation3, drugInformation4,\n",
    "    drugInformation5, drugInformation6, drugInformation7, drugInformation8\n",
    "]\n",
    "\n",
    "diagnosisRecode = [\n",
    "    'DIAG1R', 'DIAG2R', 'DIAG3R',\n",
    "    'SCOPWI1R', 'SCOPWI2R',\n",
    "    'DIAGSC1R', 'DIAGSC2R',\n",
    "    'OTHPROC1R', 'OTHPROC2R', 'OTHPROC3R', 'OTHPROC4R',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all DataFrames in the current environment\n",
    "# and clean up the environment\n",
    "for obj in dir():\n",
    "    if isinstance(eval(obj), pd.DataFrame) and not obj.startswith('_') and obj != 'dfs':\n",
    "        del globals()[obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For `dateOfVisit` variables:\n",
      "['VMONTH', 'VYEAR', 'VDAYR', 'YEAR']\n",
      "VYEAR is not in opd2010.csv\n",
      "VYEAR is not in opd2011.csv\n",
      "\n",
      "For `demographics` variables:\n",
      "['AGE', 'SEX', 'PREGNANT', 'GESTWEEK', 'ETHNIC', 'RACE', 'USETOBAC', 'NOTOBAC']\n",
      "PREGNANT is not in opd2007.csv\n",
      "PREGNANT is not in opd2008.csv\n",
      "PREGNANT is not in opd2009.csv\n",
      "PREGNANT is not in opd2010.csv\n",
      "PREGNANT is not in opd2011.csv\n",
      "GESTWEEK is not in opd2006.csv\n",
      "GESTWEEK is not in opd2007.csv\n",
      "GESTWEEK is not in opd2008.csv\n",
      "GESTWEEK is not in opd2009.csv\n",
      "GESTWEEK is not in opd2010.csv\n",
      "GESTWEEK is not in opd2011.csv\n",
      "ETHNIC is not in opd2007.csv\n",
      "ETHNIC is not in opd2008.csv\n",
      "ETHNIC is not in opd2009.csv\n",
      "ETHNIC is not in opd2010.csv\n",
      "ETHNIC is not in opd2011.csv\n",
      "RACE is not in opd2007.csv\n",
      "RACE is not in opd2008.csv\n",
      "RACE is not in opd2009.csv\n",
      "RACE is not in opd2010.csv\n",
      "RACE is not in opd2011.csv\n",
      "NOTOBAC is not in opd2007.csv\n",
      "NOTOBAC is not in opd2008.csv\n",
      "NOTOBAC is not in opd2009.csv\n",
      "NOTOBAC is not in opd2010.csv\n",
      "NOTOBAC is not in opd2011.csv\n",
      "\n",
      "For `payment` variables:\n",
      "['PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPE']\n",
      "PAYTYPE is not in opd2008.csv\n",
      "PAYTYPE is not in opd2009.csv\n",
      "PAYTYPE is not in opd2010.csv\n",
      "PAYTYPE is not in opd2011.csv\n",
      "\n",
      "For `imputedFields` variables:\n",
      "['BDATEFL', 'SEXFL', 'ETHNICFL', 'RACEFL', 'SENBEFL', 'PASTFL']\n",
      "RACEFL is not in opd2009.csv\n",
      "RACEFL is not in opd2010.csv\n",
      "RACEFL is not in opd2011.csv\n",
      "\n",
      "For `presentSymptomsStatus` variables:\n",
      "['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "CASTAGE is not in opd2009.csv\n",
      "CASTAGE is not in opd2011.csv\n",
      "DMP is not in opd2009.csv\n",
      "DMP is not in opd2010.csv\n",
      "DMP is not in opd2011.csv\n",
      "\n",
      "For `diagnosticScreeningServices` variables:\n",
      "['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'SCOPEWI1', 'SCOPEWI2', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'DIAGSC1', 'DIAGSC2']\n",
      "ULTRASND is not in opd2007.csv\n",
      "ULTRASND is not in opd2008.csv\n",
      "ULTRASND is not in opd2009.csv\n",
      "ULTRASND is not in opd2010.csv\n",
      "ULTRASND is not in opd2011.csv\n",
      "ELECTROL is not in opd2009.csv\n",
      "ELECTROL is not in opd2010.csv\n",
      "ELECTROL is not in opd2011.csv\n",
      "SCOPEWI1 is not in opd2009.csv\n",
      "SCOPEWI1 is not in opd2010.csv\n",
      "SCOPEWI1 is not in opd2011.csv\n",
      "SCOPEWI2 is not in opd2009.csv\n",
      "SCOPEWI2 is not in opd2010.csv\n",
      "SCOPEWI2 is not in opd2011.csv\n",
      "PAPCONV is not in opd2011.csv\n",
      "PAPLIQ is not in opd2011.csv\n",
      "PAPUNSP is not in opd2011.csv\n",
      "SPIRO is not in opd2009.csv\n",
      "SPIRO is not in opd2010.csv\n",
      "SPIRO is not in opd2011.csv\n",
      "DIAGSC1 is not in opd2009.csv\n",
      "DIAGSC1 is not in opd2010.csv\n",
      "DIAGSC1 is not in opd2011.csv\n",
      "DIAGSC2 is not in opd2009.csv\n",
      "DIAGSC2 is not in opd2010.csv\n",
      "DIAGSC2 is not in opd2011.csv\n",
      "\n",
      "For `nonMedicationTreatments` variables:\n",
      "['CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'OTHPROC1', 'OTHPROC2', 'OTHPROC3', 'OTHPROC4']\n",
      "HOSPICE is not in opd2009.csv\n",
      "HOSPICE is not in opd2010.csv\n",
      "HOSPICE is not in opd2011.csv\n",
      "RADTHER is not in opd2009.csv\n",
      "ORTHO is not in opd2009.csv\n",
      "ORTHO is not in opd2010.csv\n",
      "ORTHO is not in opd2011.csv\n",
      "OTHPROC1 is not in opd2009.csv\n",
      "OTHPROC1 is not in opd2010.csv\n",
      "OTHPROC1 is not in opd2011.csv\n",
      "OTHPROC2 is not in opd2009.csv\n",
      "OTHPROC2 is not in opd2010.csv\n",
      "OTHPROC2 is not in opd2011.csv\n",
      "OTHPROC3 is not in opd2009.csv\n",
      "OTHPROC3 is not in opd2010.csv\n",
      "OTHPROC3 is not in opd2011.csv\n",
      "OTHPROC4 is not in opd2009.csv\n",
      "OTHPROC4 is not in opd2010.csv\n",
      "OTHPROC4 is not in opd2011.csv\n",
      "\n",
      "For `visitDisposition` variables:\n",
      "['NODISP', 'NOFU', 'RETPRN', 'REFOTHMD', 'RETAPPT', 'TELEPHON', 'REFERED', 'ADMITHOS', 'OTHDISP']\n",
      "NOFU is not in opd2009.csv\n",
      "NOFU is not in opd2010.csv\n",
      "NOFU is not in opd2011.csv\n",
      "RETPRN is not in opd2009.csv\n",
      "RETPRN is not in opd2010.csv\n",
      "RETPRN is not in opd2011.csv\n",
      "TELEPHON is not in opd2009.csv\n",
      "TELEPHON is not in opd2010.csv\n",
      "TELEPHON is not in opd2011.csv\n",
      "REFERED is not in opd2009.csv\n",
      "REFERED is not in opd2010.csv\n",
      "REFERED is not in opd2011.csv\n",
      "ADMITHOS is not in opd2009.csv\n",
      "ADMITHOS is not in opd2010.csv\n",
      "ADMITHOS is not in opd2011.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up a dictionary of variables\n",
    "variables = {\n",
    "    'dateOfVisit': dateOfVisit,\n",
    "    'demographics': demographics,\n",
    "    'payment': payment,\n",
    "    'visitReason': visitReason,\n",
    "    'patientClinicHistory': patientClinicHistory,\n",
    "    'vitalSigns': vitalSigns,\n",
    "    'imputedFields': imputedFields,\n",
    "    'physicianDiagnoses': physicianDiagnoses,\n",
    "    'differentialDiagnoses': differentialDiagnoses,\n",
    "    'presentSymptomsStatus': presentSymptomsStatus,\n",
    "    'diagnosticScreeningServices': diagnosticScreeningServices,\n",
    "    'healthEducation': healthEducation,\n",
    "    'nonMedicationTreatments': nonMedicationTreatments,\n",
    "    'medicationsAndImmunizations': medicationsAndImmunizations,\n",
    "    'providersSeen': providersSeen,\n",
    "    'visitDisposition': visitDisposition,\n",
    "    #'drugInformation': drugInformation,\n",
    "    #'diagnosisRecode': diagnosisRecode\n",
    "\n",
    "}\n",
    "\n",
    "# Check the existence of all variables among the DataFrames in `dfs`\n",
    "for var_name, var in variables.items():\n",
    "    # Continue if all variables are in all the DataFrames\n",
    "    if all(all(v in df.columns for v in var) for df in dfs): continue\n",
    "\n",
    "    # Print the DataFrames that do not have all the variables\n",
    "    print(f'For `{var_name}` variables:\\n{var}')\n",
    "    for v in var:\n",
    "        for df in dfs:\n",
    "            if v not in df.columns:\n",
    "                print(f'{v} is not in {df.file.unique()[0]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Handling missing variables in the 2007-2011 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the list of DataFrames to dfs_cleaned\n",
    "dfs_cleaned = [df.copy() for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2010,\n",
    "# The year of visit item (VYEAR) is no longer included on the public use file. Although the NHAMCS\n",
    "# reporting periods will often begin in the last week of December and end in the last week of the\n",
    "# following December, they are designed to yield statistics that are representative of the actual\n",
    "# calendar year. The survey variable YEAR continues to be on the file and all visit dates may be\n",
    "# assumed to reflect the calendar year. If more specific information is required, it is necessary to\n",
    "# access the data through the NCHS Research Data Center.\n",
    "\n",
    "# Impute the `VYEAR` column with the year from the `YEAR` column for the years 2010 and 2011\n",
    "for df in dfs_cleaned:\n",
    "    if 'VYEAR' not in df.columns:\n",
    "        df['VYEAR'] = df['YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2007,\n",
    "# Items \"Is female patient pregnant, and, if so, specify gestation week.\" are deleted.\n",
    "\n",
    "# Remove the `PREGNANT` and `GESTWEEK` columns from the `demographics` list\n",
    "demographics.remove('PREGNANT')\n",
    "demographics.remove('GESTWEEK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2007,\n",
    "# The high amounts of missing data are of concern both from a data collection standpoint as well as an\n",
    "# analytic one. In order to highlight this problem for data users, an unimputed race variable has been added\n",
    "# to each file, along with an unimputed ethnicity variable. Imputed race and ethnicity variables are included\n",
    "# as usual.\n",
    "\n",
    "# Remove `ETHNICFL` and `RACEFL` from the `imputedFields` list\n",
    "imputedFields.remove('ETHNICFL')\n",
    "imputedFields.remove('RACEFL')\n",
    "\n",
    "# Replace the `RACE` and `ETHNIC` columns with the unimputed values from `RACEUN` and `ETHUN` columns from the year 2007\n",
    "for df in dfs_cleaned:\n",
    "    if 'RACEUN' in df.columns:\n",
    "        df['RACE'] = df['RACEUN']\n",
    "        df['ETHNIC'] = df['ETHUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2007,\n",
    "# Tobacco use – [USETOBAC] The format of this item was modified to three checkboxes:\n",
    "# not current, current and unknown. In 2006, if “Not Current” had been checked, two\n",
    "# additional items, “Never and “Former” were asked. These were deleted for 2007.\n",
    "\n",
    "# Remove the `NOTOBAC` column from the `demographics` list\n",
    "demographics.remove('NOTOBAC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2008,\n",
    "# the variable PAYTYPE (Expected Primary Source of Payment for this Visit) has been renamed as \n",
    "# PAYTYPER (Recoded Expected Primary Source of Payment for this Visit).\n",
    "# This is intended to emphasize the fact that PAYTYPER is a recoded item which uses a hierarchy\n",
    "# to assign a primary expected source of payment based on the collection of multiple expected\n",
    "# sources of payment.\n",
    "\n",
    "# Replace `PAYTYPE` with `PAYTYPER` in the `payment` list\n",
    "payment.remove('PAYTYPE')\n",
    "payment.append('PAYTYPER')\n",
    "\n",
    "# Rename `PAYTYPE` to `PAYTYPER` in the DataFrames for year 2006 and 2007\n",
    "for df in dfs_cleaned:\n",
    "    if 'PAYTYPE' in df.columns:\n",
    "        df.rename(columns={'PAYTYPE': 'PAYTYPER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# The Services section reflects responses to both item 7, Diagnostic/Screening Services,\n",
    "# and item 9, Non-Medication Treatment.\n",
    "\n",
    "# Combine the `diagnosticScreeningServices` and `nonMedicationTreatments` lists into a single list `services`\n",
    "services = diagnosticScreeningServices + nonMedicationTreatments\n",
    "\n",
    "# Remove `nonMedicationTreatments` from the `variables` dictionary\n",
    "del variables['nonMedicationTreatments']\n",
    "\n",
    "# Replace `diagnosticScreeningServices` with `services` in the `variables` dictionary\n",
    "new_variables = {}\n",
    "for var_name, var in variables.items():\n",
    "    if var_name == 'diagnosticScreeningServices':\n",
    "        new_variables['services'] = services\n",
    "    else:\n",
    "        new_variables[var_name] = var\n",
    "\n",
    "variables = new_variables\n",
    "del new_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2007,\n",
    "# The previous single ultrasound checkbox was replaced with two checkboxes,\n",
    "# one for echocardiogram [ECHOCARD], the other for other ultrasound [OTHULTRA].\n",
    "\n",
    "# Add `ECHOCARD` and `OTHULTRA` to the `services` list\n",
    "services.append('ECHOCARD')\n",
    "services.append('OTHULTRA')\n",
    "\n",
    "# Assign 'Yes' to the `ULTRASND` column if either `ECHOCARD` or `OTHULTRA` is 'Yes'\n",
    "# Assign 'No' to the `ULTRASND` column if both `ECHOCARD` and `OTHULTRA` are 'No'\n",
    "# Assign NaN to the `ULTRASND` column if both `ECHOCARD` and `OTHULTRA` are NaN\n",
    "for df in dfs_cleaned:\n",
    "    if 'ECHOCARD' in df.columns and 'OTHULTRA' in df.columns:\n",
    "        df['ULTRASND'] = df['ECHOCARD'].combine_first(df['OTHULTRA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `SCOPEWI1` and `SCOPEWI1` in the year 2007 and 2008 represent two Scope Procedures written-in fields.\n",
    "# `DIAGSC1` and `DIAGSC2` in the year 2007 and 2008 represent two other Diagnostic Screening Procedures written-in fields.\n",
    "# `OTHPROC1` to `OTHPROC4` in the year 2007 and 2008 represent four outher Surgical or Non-surgical Procedures written-in fields.\n",
    "# A write-in box for site of biopsy was added to the existing checkbox for biopsy [BIOPSYWI] in the year 2007 and 2008.\n",
    "# From year 2009,\n",
    "# These eight fields are replaced by `PROC1` to `PROC9`,\n",
    "# presenting a complete picture of the number and type of procedures reported at a visit.\n",
    "# Up to 2 scope procedures, 1 biopsy site, 2 other diagnostic/screening tests/services,\n",
    "# and up to 4 procedures in the non-medication treatment item could be coded\n",
    "# for each outpatient department visit.\n",
    "\n",
    "# Add columns `PROC1` to `PROC9` to the `services` list\n",
    "services.extend([f'PROC{i}' for i in range(1, 10)])\n",
    "\n",
    "# Remove `SCOPEWI1` and `SCOPEWI2` from the `service` list\n",
    "services.remove('SCOPEWI1')\n",
    "services.remove('SCOPEWI2')\n",
    "\n",
    "# Remove `DIAGSC1` and `DIAGSC2` from the `service` list\n",
    "services.remove('DIAGSC1')\n",
    "services.remove('DIAGSC2')\n",
    "\n",
    "# Remove `OTHPROC1` to `OTHPROC4` from the `service` list\n",
    "services.remove('OTHPROC1')\n",
    "services.remove('OTHPROC2')\n",
    "services.remove('OTHPROC3')\n",
    "services.remove('OTHPROC4')\n",
    "\n",
    "# Renew the `services` list in the `variables` dictionary\n",
    "variables['services'] = services\n",
    "\n",
    "# Add `PROC1` to `PROC9` columns to the DataFrames for year 2007 and 2008,\n",
    "# assign the values from `SCOPEWI1` and `SCOPEWI2` to the `PROC1` and `PROC2` columns\n",
    "# assign the values from `BIOPSYWI` to the `PROC3` column\n",
    "# assign the values from `DIAGSC1` and `DIAGSC2` to the `PROC4` and `PROC5` columns\n",
    "# assign the values from `OTHPROC1` to `OTHPROC4` to the `PROC6` to `PROC9` columns\n",
    "for df in dfs_cleaned:\n",
    "    if 'SCOPEWI1' in df.columns and 'SCOPEWI2' in df.columns:\n",
    "        df['PROC1'] = df['SCOPEWI1']\n",
    "        df['PROC2'] = df['SCOPEWI2']\n",
    "    else:\n",
    "        df['PROC1'] = None\n",
    "        df['PROC2'] = None\n",
    "\n",
    "    if 'BIOPSYWI' in df.columns: df['PROC3'] = df['BIOPSYWI']\n",
    "    else: df['PROC3'] = None\n",
    "\n",
    "    if 'DIAGSC1' in df.columns and 'DIAGSC2' in df.columns:\n",
    "        df['PROC4'] = df['DIAGSC1']\n",
    "        df['PROC5'] = df['DIAGSC2']\n",
    "    else:\n",
    "        df['PROC4'] = None\n",
    "        df['PROC5'] = None\n",
    "\n",
    "    if 'OTHPROC1' in df.columns: df['PROC6'] = df['OTHPROC1']\n",
    "    else: df['PROC6'] = None\n",
    "\n",
    "    if 'OTHPROC2' in df.columns: df['PROC7'] = df['OTHPROC2']\n",
    "    else: df['PROC7'] = None\n",
    "\n",
    "    if 'OTHPROC3' in df.columns: df['PROC8'] = df['OTHPROC3']\n",
    "    else: df['PROC8'] = None\n",
    "\n",
    "    if 'OTHPROC4' in df.columns: df['PROC9'] = df['OTHPROC4']\n",
    "    else: df['PROC9'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the year 2011,\n",
    "# In Diagnostic/Screening Services, the checkbox “Pap test” replaces the 2010 checkboxes\n",
    "# for “Pap test – conventional”, “Pap test – liquid-based”, and “Pap test – unspecified.”\n",
    "\n",
    "# Rename `PAP` to `PAPUNSP` in the 2011 DataFrame\n",
    "for df in dfs_cleaned:\n",
    "    if 'PAP' in df.columns:\n",
    "        df.rename(columns={'PAP': 'PAPUNSP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# In item 12, Visit Disposition, checkboxes for\n",
    "# no follow-up planned, return if needed PRN, and telephone follow-up planned\n",
    "# were removed.\n",
    "\n",
    "# Remove `NOFU`, `RETPRN`, and `TELEPHON` from the `visitDisposition` list\n",
    "visitDisposition.remove('NOFU')\n",
    "visitDisposition.remove('RETPRN')\n",
    "visitDisposition.remove('TELEPHON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# In item 12, Visit Disposition, checkboxes used in 2008 for \n",
    "# “refer to emergency department” and “admit to hospital”\n",
    "# were combined into a single category for 2009: Refer to ER/Admit to hospital\n",
    "\n",
    "# Remove `REFERED` and `ADMITHOS` from the `visitDisposition` list\n",
    "visitDisposition.remove('REFERED')\n",
    "visitDisposition.remove('ADMITHOS')\n",
    "\n",
    "# Add `ERADMHOS` to the `visitDisposition` list\n",
    "visitDisposition.append('ERADMHOS')\n",
    "\n",
    "# Add `ERADMHOS` column to the DataFrames for year 2006 to 2008\n",
    "# Assign the values from `REFERED` and `ADMITHOS` to the `ERADMHOS` column\n",
    "for df in dfs_cleaned:\n",
    "    if 'REFERED' in df.columns and 'ADMITHOS' in df.columns:\n",
    "        df['ERADMHOS'] = df['REFERED'].combine_first(df['ADMITHOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For `presentSymptomsStatus` variables:\n",
      "['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "CASTAGE is not in opd2009.csv\n",
      "CASTAGE is not in opd2011.csv\n",
      "DMP is not in opd2009.csv\n",
      "DMP is not in opd2010.csv\n",
      "DMP is not in opd2011.csv\n",
      "\n",
      "For `services` variables:\n",
      "['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9']\n",
      "ELECTROL is not in opd2009.csv\n",
      "ELECTROL is not in opd2010.csv\n",
      "ELECTROL is not in opd2011.csv\n",
      "PAPCONV is not in opd2011.csv\n",
      "PAPLIQ is not in opd2011.csv\n",
      "SPIRO is not in opd2009.csv\n",
      "SPIRO is not in opd2010.csv\n",
      "SPIRO is not in opd2011.csv\n",
      "HOSPICE is not in opd2009.csv\n",
      "HOSPICE is not in opd2010.csv\n",
      "HOSPICE is not in opd2011.csv\n",
      "RADTHER is not in opd2009.csv\n",
      "ORTHO is not in opd2009.csv\n",
      "ORTHO is not in opd2010.csv\n",
      "ORTHO is not in opd2011.csv\n",
      "ECHOCARD is not in opd2006.csv\n",
      "OTHULTRA is not in opd2006.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the existence of all variables among the DataFrames in `dfs_cleaned`\n",
    "# to verify the result of the cleaning process\n",
    "\n",
    "for var_name, var in variables.items():\n",
    "    # Continue if all variables are in all the DataFrames\n",
    "    if all(all(v in df.columns for v in var) for df in dfs_cleaned): continue\n",
    "\n",
    "    # Print the DataFrames that do not have all the variables\n",
    "    print(f'For `{var_name}` variables:\\n{var}')\n",
    "    for v in var:\n",
    "        for df in dfs_cleaned:\n",
    "            if v not in df.columns:\n",
    "                print(f'{v} is not in {df.file.unique()[0]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For year 2009 and 2011,\n",
    "# “Regardless of the diagnoses written in 5a, does the patient now have:”,\n",
    "# the sub-item for cancer stage was removed.\n",
    "\n",
    "# We would want to keep the `CASTAGE` variable for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# “Status of patient enrollment in a disease management program\n",
    "# for any of the conditions marked in 5b” was removed.\n",
    "\n",
    "# We would want to keep the `DMP` variable for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# In Diagnostic /Screening Services, checkboxes for PET scan, electrolytes, and\n",
    "# spirometry/pulmonary function test were removed.\n",
    "\n",
    "# We would want to keep the `ELECTROL` and `SPIRO` variables for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "# In Non-medication Treatment, checkboxes for\n",
    "# orthopedic care, hospice care, and radiation therapy were removed.\n",
    "# Radiation therapy was added back to the form in 2010\n",
    "\n",
    "# We would want to keep the `ORTHO`, `HOSPICE`, and `RADTHER` variables for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of variables is:\n",
      "\n",
      "dateOfVisit: ['VMONTH', 'VYEAR', 'VDAYR', 'YEAR']\n",
      "\n",
      "demographics: ['AGE', 'SEX', 'ETHNIC', 'RACE', 'USETOBAC']\n",
      "\n",
      "payment: ['PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPER']\n",
      "\n",
      "visitReason: ['INJDET', 'INJURY', 'MAJOR', 'RFV1', 'RFV2', 'RFV3']\n",
      "\n",
      "patientClinicHistory: ['SENBEFOR', 'PASTVIS']\n",
      "\n",
      "vitalSigns: ['HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS']\n",
      "\n",
      "imputedFields: ['BDATEFL', 'SEXFL', 'SENBEFL', 'PASTFL']\n",
      "\n",
      "physicianDiagnoses: ['DIAG1', 'DIAG2', 'DIAG3']\n",
      "\n",
      "differentialDiagnoses: ['PRDIAG1', 'PRDIAG2', 'PRDIAG3']\n",
      "\n",
      "presentSymptomsStatus: ['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "\n",
      "services: ['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9']\n",
      "\n",
      "healthEducation: ['ASTHMAED', 'DIETNUTR', 'EXERCISE', 'GRWTHDEV', 'INJPREV', 'STRESMGT', 'TOBACED', 'WTREDUC', 'OTHLTHED']\n",
      "\n",
      "medicationsAndImmunizations: ['MED1', 'MED2', 'MED3', 'MED4', 'MED5', 'MED6', 'MED7', 'MED8', 'NCMED1', 'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8', 'NUMNEW', 'NUMCONT']\n",
      "\n",
      "providersSeen: ['NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV']\n",
      "\n",
      "visitDisposition: ['NODISP', 'REFOTHMD', 'RETAPPT', 'OTHDISP', 'ERADMHOS']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The number of variables in total is:\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# Print the update lists of variables\n",
    "print('The updated list of variables is:')\n",
    "print()\n",
    "for var_name, var in variables.items():\n",
    "    print(f'{var_name}: {var}')\n",
    "    print()\n",
    "\n",
    "print('-' * 80)\n",
    "\n",
    "# Print the number of variables in total\n",
    "print('The number of variables in total is:')\n",
    "print(sum(len(var) for var in variables.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Add new variables in the 2007-2011 dataframes to the lists of variables\n",
    "The initial lists of variables are created based on the 2006 data and document.\n",
    "\n",
    "There are some new fields added to the survey and data since 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2007,\n",
    "\n",
    "# In Diagnostic/Screening Services – New checkboxes were added for\n",
    "# CT scan [CATSCAN], PET scan [PETSCAN], and pregnancy test [PREGTEST]\n",
    "\n",
    "# PET scan [PETSCAN] is removed again from year 2009 to 2011, So we don't add it to the `services` list.\n",
    "\n",
    "# Add `CATSCAN`, `PETSCAN`, `PREGTEST`, and `BIOPSYWI` to the `services` list\n",
    "services.append('CATSCAN')\n",
    "#services.append('PETSCAN')\n",
    "services.append('PREGTEST')\n",
    "\n",
    "\n",
    "# In Providers – A checkbox was added for mental health provider [MHP].\n",
    "\n",
    "# Add `MHP` to the `providersSeen` list\n",
    "providersSeen.append('MHP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From year 2009,\n",
    "\n",
    "# In item 7, Diagnostic /Screening Services, there are new checkboxes for:\n",
    "# Foot examination, Retinal examination, HIV test\n",
    "\n",
    "# Add `FOOT`, `RETINAL`, `HIVTEST` to the `services` list\n",
    "services.append('FOOT')\n",
    "services.append('RETINAL')\n",
    "services.append('HIVTEST')\n",
    "\n",
    "\n",
    "# In item 9, Non-medication Treatment, there are new checkboxes for:\n",
    "# Cast, Splint or wrap\n",
    "\n",
    "# Add `CAST`, `SPLINT` to the `services` list\n",
    "services.append('CAST')\n",
    "services.append('SPLINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For `presentSymptomsStatus` variables:\n",
      "['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "CASTAGE is not in opd2009.csv\n",
      "CASTAGE is not in opd2011.csv\n",
      "DMP is not in opd2009.csv\n",
      "DMP is not in opd2010.csv\n",
      "DMP is not in opd2011.csv\n",
      "\n",
      "For `services` variables:\n",
      "['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9', 'CATSCAN', 'PREGTEST', 'FOOT', 'RETINAL', 'HIVTEST', 'CAST', 'SPLINT']\n",
      "ELECTROL is not in opd2009.csv\n",
      "ELECTROL is not in opd2010.csv\n",
      "ELECTROL is not in opd2011.csv\n",
      "PAPCONV is not in opd2011.csv\n",
      "PAPLIQ is not in opd2011.csv\n",
      "SPIRO is not in opd2009.csv\n",
      "SPIRO is not in opd2010.csv\n",
      "SPIRO is not in opd2011.csv\n",
      "HOSPICE is not in opd2009.csv\n",
      "HOSPICE is not in opd2010.csv\n",
      "HOSPICE is not in opd2011.csv\n",
      "RADTHER is not in opd2009.csv\n",
      "ORTHO is not in opd2009.csv\n",
      "ORTHO is not in opd2010.csv\n",
      "ORTHO is not in opd2011.csv\n",
      "ECHOCARD is not in opd2006.csv\n",
      "OTHULTRA is not in opd2006.csv\n",
      "CATSCAN is not in opd2006.csv\n",
      "PREGTEST is not in opd2006.csv\n",
      "FOOT is not in opd2006.csv\n",
      "FOOT is not in opd2007.csv\n",
      "FOOT is not in opd2008.csv\n",
      "RETINAL is not in opd2006.csv\n",
      "RETINAL is not in opd2007.csv\n",
      "RETINAL is not in opd2008.csv\n",
      "HIVTEST is not in opd2006.csv\n",
      "HIVTEST is not in opd2007.csv\n",
      "HIVTEST is not in opd2008.csv\n",
      "CAST is not in opd2006.csv\n",
      "CAST is not in opd2007.csv\n",
      "CAST is not in opd2008.csv\n",
      "SPLINT is not in opd2006.csv\n",
      "SPLINT is not in opd2007.csv\n",
      "SPLINT is not in opd2008.csv\n",
      "\n",
      "For `providersSeen` variables:\n",
      "['NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV', 'MHP']\n",
      "MHP is not in opd2006.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the existence of all variables among the DataFrames in `dfs_cleaned`\n",
    "# to verify the result of the cleaning process\n",
    "\n",
    "for var_name, var in variables.items():\n",
    "    # Continue if all variables are in all the DataFrames\n",
    "    if all(all(v in df.columns for v in var) for df in dfs_cleaned): continue\n",
    "\n",
    "    # Print the DataFrames that do not have all the variables\n",
    "    print(f'For `{var_name}` variables:\\n{var}')\n",
    "    for v in var:\n",
    "        for df in dfs_cleaned:\n",
    "            if v not in df.columns:\n",
    "                print(f'{v} is not in {df.file.unique()[0]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of variables is:\n",
      "\n",
      "dateOfVisit: ['VMONTH', 'VYEAR', 'VDAYR', 'YEAR']\n",
      "\n",
      "demographics: ['AGE', 'SEX', 'ETHNIC', 'RACE', 'USETOBAC']\n",
      "\n",
      "payment: ['PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPER']\n",
      "\n",
      "visitReason: ['INJDET', 'INJURY', 'MAJOR', 'RFV1', 'RFV2', 'RFV3']\n",
      "\n",
      "patientClinicHistory: ['SENBEFOR', 'PASTVIS']\n",
      "\n",
      "vitalSigns: ['HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS']\n",
      "\n",
      "imputedFields: ['BDATEFL', 'SEXFL', 'SENBEFL', 'PASTFL']\n",
      "\n",
      "physicianDiagnoses: ['DIAG1', 'DIAG2', 'DIAG3']\n",
      "\n",
      "differentialDiagnoses: ['PRDIAG1', 'PRDIAG2', 'PRDIAG3']\n",
      "\n",
      "presentSymptomsStatus: ['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "\n",
      "services: ['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9', 'CATSCAN', 'PREGTEST', 'FOOT', 'RETINAL', 'HIVTEST', 'CAST', 'SPLINT']\n",
      "\n",
      "healthEducation: ['ASTHMAED', 'DIETNUTR', 'EXERCISE', 'GRWTHDEV', 'INJPREV', 'STRESMGT', 'TOBACED', 'WTREDUC', 'OTHLTHED']\n",
      "\n",
      "medicationsAndImmunizations: ['MED1', 'MED2', 'MED3', 'MED4', 'MED5', 'MED6', 'MED7', 'MED8', 'NCMED1', 'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8', 'NUMNEW', 'NUMCONT']\n",
      "\n",
      "providersSeen: ['NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV', 'MHP']\n",
      "\n",
      "visitDisposition: ['NODISP', 'REFOTHMD', 'RETAPPT', 'OTHDISP', 'ERADMHOS']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The number of variables in total is:\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "# Print the update lists of variables\n",
    "print('The updated list of variables is:')\n",
    "print()\n",
    "for var_name, var in variables.items():\n",
    "    print(f'{var_name}: {var}')\n",
    "    print()\n",
    "\n",
    "print('-' * 80)\n",
    "\n",
    "# Print the number of variables in total\n",
    "print('The number of variables in total is:')\n",
    "print(sum(len(var) for var in variables.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Merge the dataframes with the selected variables of interest and clean up the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged DataFrame is:\n",
      "(203988, 161)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all selected variables of interest into a list\n",
    "selected_vars = list()\n",
    "for var in variables.values():\n",
    "    selected_vars.extend(var)\n",
    "\n",
    "# Add in the `file` column to the list of selected variables\n",
    "selected_vars = ['file'] + selected_vars\n",
    "\n",
    "# Merge the DataFrames with the selected variables of interest\n",
    "df = pd.concat(dfs_cleaned, ignore_index=True)\n",
    "df = df[selected_vars]\n",
    "\n",
    "# Check the shape of the merged DataFrame\n",
    "print('The shape of the merged DataFrame is:')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns that contain both numeric and non-numeric values are:\n",
      "['AGE', 'PASTVIS', 'HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS', 'DIAG1', 'DIAG2', 'DIAG3', 'TOTCHRON', 'PROC6', 'PROC7', 'MED1', 'MED2', 'MED3', 'MED4', 'MED5']\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values of each column in the merged DataFrame,\n",
    "# and find those columns that the unique values include both numeric and non-numeric values\n",
    "\n",
    "# Get the unique values of each column\n",
    "unique_values = df.apply(lambda x: x.dropna().unique())\n",
    "\n",
    "# Go through the unique values of each column,\n",
    "# and find those columns that contains both numeric and non-numeric values using Regular Expression\n",
    "mixed_value_cols = []\n",
    "for col, values in unique_values.items():\n",
    "    #if any(re.search(r'[\\d.]', str(v)) for v in values) and any(re.search(r'[^\\d.]', str(v)) for v in values):\n",
    "    if any(re.fullmatch(r'\\d*\\.?\\d+', str(v)) for v in values) and any(not re.fullmatch(r'\\d*\\.?\\d+', str(v)) for v in values):\n",
    "        mixed_value_cols.append(col)\n",
    "\n",
    "# Print the columns that contain both numeric and non-numeric values\n",
    "print('The columns that contain both numeric and non-numeric values are:')\n",
    "print(mixed_value_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `AGE` column are:\n",
      "['37.0' '48.0' '40.0' '46.0' '34.0' '83.0' '45.0' '65.0' '26.0' '39.0'\n",
      " '80.0' '16.0' '81.0' '57.0' '30.0' '61.0' '58.0' '50.0' '91.0' '20.0'\n",
      " '56.0' '59.0' '28.0' '35.0' '66.0' '69.0' '64.0' '51.0' '25.0' '29.0'\n",
      " '23.0' '27.0' '22.0' '41.0' '31.0' '36.0' '42.0' '32.0' '24.0' '33.0'\n",
      " '38.0' '44.0' '21.0' '47.0' '19.0' '76.0' '18.0' '49.0' '43.0' '52.0'\n",
      " '55.0' '74.0' '60.0' '54.0' '63.0' '67.0' '85.0' '17.0' '72.0' '62.0'\n",
      " '70.0' '87.0' '86.0' '75.0' '84.0' '68.0' '71.0' '77.0' '79.0' '78.0'\n",
      " '6.0' '9.0' 'Under one year' '10.0' '1.0' '5.0' '11.0' '53.0' '73.0'\n",
      " '8.0' '3.0' '2.0' '7.0' '4.0' '15.0' '89.0' '14.0' '82.0' '12.0' '88.0'\n",
      " '90.0' '92.0' '96.0' '13.0' '100 years and over' '94.0' '93.0' '95.0'\n",
      " '97.0' '98.0' '99.0' '91 years or older']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `AGE` column\n",
    "print('The values of those including non-numeric values in the `AGE` column are:')\n",
    "print(df.loc[df['BMI'].astype(str).str.contains(r'[^\\d.]'), 'AGE'].unique())\n",
    "\n",
    "# !!! Replace 'Under one year' with 1 in the `AGE` column\n",
    "df['AGE'] = df['AGE'].replace('Under one year', 1)\n",
    "\n",
    "# Replace '91 years or older' with 91 in the `AGE` column\n",
    "df['AGE'] = df['AGE'].replace('91 years or older', 91)\n",
    "\n",
    "# Replace '100 years and over' with 100 in the `AGE` column\n",
    "df['AGE'] = df['AGE'].replace('100 years and over', 100)\n",
    "\n",
    "# Cast the `AGE` column to float\n",
    "df['AGE'] = df['AGE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `PASTVIS` column are:\n",
      "['3-5' '1-2' '6 or more' 'Not applicable' nan '99 visits or more'\n",
      " '75 visits or more (CLINTYPE 2,6)' '34 visits or more (CLINTYPE 1,3,4)']\n",
      "\n",
      "The value counts of `SENBEFOR` for the rows where `PASTVIS` is `Not applicable` are:\n",
      "SENBEFOR\n",
      "No, new patient    39270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The values of those including non-numeric values in the `PASTVIS` column are:\n",
      "['3-5' '1-2' '6 or more' nan '99 visits or more'\n",
      " '75 visits or more (CLINTYPE 2,6)' '34 visits or more (CLINTYPE 1,3,4)']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `PASTVIS` column\n",
    "print('The values of those including non-numeric values in the `PASTVIS` column are:')\n",
    "print(df.loc[df['PASTVIS'].astype(str).str.contains(r'[^\\d.]'), 'PASTVIS'].unique())\n",
    "\n",
    "# Check the value counts of `SENBEFOR` for the rows where `PASTVIS` is 'Not applicable'\n",
    "print()\n",
    "print('The value counts of `SENBEFOR` for the rows where `PASTVIS` is `Not applicable` are:')\n",
    "print(df.loc[df['PASTVIS'] == 'Not applicable', 'SENBEFOR'].value_counts())\n",
    "\n",
    "\n",
    "# ITEM 4b. HAS THE PATIENT BEEN SEEN IN THIS CLINIC BEFORE?\n",
    "# “Seen” means “provided care for” at any time in the past. Mark “Yes, established patient” if the patient\n",
    "# was seen before by any physician or staff member in the clinic. Exclude this visit.\n",
    "# Mark “No, new patient” if the patient has not been seen in the clinic before.\n",
    "# If “Yes” is checked, also indicate approximately how many past visits the patient has made to this clinic\n",
    "# within the last 12 months using the check boxes provided. Do not include the current visit in your total. If\n",
    "# you cannot determine how many past visits were made, then please mark “Unknown.” Include all visits to\n",
    "# other physicians or health care providers in this clinic.\n",
    "\n",
    "# Replace the value 'Not applicable' with 0 in the `PASTVIS` column,\n",
    "# since 'Not applicable' means, 'No, new patient' has been checked in the `SENBEFOR` column.\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('Not applicable', 0)\n",
    "\n",
    "# Check the values of those including non-numeric values in the `PASTVIS` column\n",
    "print()\n",
    "print('The values of those including non-numeric values in the `PASTVIS` column are:')\n",
    "print(df.loc[df['PASTVIS'].astype(str).str.contains(r'[^\\d.]'), 'PASTVIS'].unique())\n",
    "\n",
    "# ! Replace the value '99 visits or more' with 99 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('99 visits or more', 99)\n",
    "\n",
    "# ! Replace the value '75 visits or more (CLINTYPE 2,6)' with 75 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('75 visits or more (CLINTYPE 2,6)', 75)\n",
    "\n",
    "# ! Replace the value '34 visits or more' and '34 visits or more (CLINTYPE 1,3,4)' with 34 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('34 visits or more', 34)\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('34 visits or more (CLINTYPE 1,3,4)', 34)\n",
    "\n",
    "# !!! Replace the value '6 visits or more' and '6 or more' with 6 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('6 visits or more', 6)\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('6 or more', 6)\n",
    "\n",
    "# !!! Replace the value '1-2' with 1.5 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('1-2', 1.5)\n",
    "\n",
    "# !!! Replace the value '3-5' with 4 in the `PASTVIS` column\n",
    "df['PASTVIS'] = df['PASTVIS'].replace('3-5', 4)\n",
    "\n",
    "# Cast the `PASTVIS` column to float\n",
    "df['PASTVIS'] = df['PASTVIS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `HTIN` column are:\n",
      "['Blank' '72 inches or more (females)' '77 inches or more (males)']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `HTIN` column\n",
    "print('The values of those including non-numeric values in the `HTIN` column are:')\n",
    "print(df.loc[df['HTIN'].astype(str).str.contains(r'[^\\d.]'), 'HTIN'].unique())\n",
    "\n",
    "# Replace 'Blank' with Nan in the `HTIN` column\n",
    "df['HTIN'] = df['HTIN'].replace('Blank', float('nan'))\n",
    "\n",
    "# !!! Replace '72 inches or more (females)' with 72 in the `HTIN` column\n",
    "df['HTIN'] = df['HTIN'].replace('72 inches or more (females)', 72)\n",
    "\n",
    "# !!! Replace '77 inches or more (males)' with 77 in the `HTIN` column\n",
    "df['HTIN'] = df['HTIN'].replace('77 inches or more (males)', 77)\n",
    "\n",
    "# Cast the `HTIN` column to float\n",
    "df['HTIN'] = df['HTIN'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `WTLB` column are:\n",
      "['Blank' '500 lbs. or more' '385 lbs. or more']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `WTLB` column\n",
    "print('The values of those including non-numeric values in the `WTLB` column are:')\n",
    "print(df.loc[df['WTLB'].astype(str).str.contains(r'[^\\d.]'), 'WTLB'].unique())\n",
    "\n",
    "# Replace 'Blank' with Nan in the `WTLB` column\n",
    "df['WTLB'] = df['WTLB'].replace('Blank', float('nan'))\n",
    "\n",
    "# !!! Replace '500 lbs. or more' with 500 in the `WTLB` column\n",
    "df['WTLB'] = df['WTLB'].replace('500 lbs. or more', 500)\n",
    "\n",
    "# !!! Replace '385 lbs. or more' with 385 in the `WTLB` column\n",
    "df['WTLB'] = df['WTLB'].replace('385 lbs. or more', 385)\n",
    "\n",
    "# Cast the `WTLB` column to float\n",
    "df['WTLB'] = df['WTLB'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `BMI` column are:\n",
      "['Blank' 'Not applicable' 'Not calculated' 'Missing data']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `BMI` column\n",
    "print('The values of those including non-numeric values in the `BMI` column are:')\n",
    "print(df.loc[df['BMI'].astype(str).str.contains(r'[^\\d.]'), 'BMI'].unique())\n",
    "\n",
    "# Replace non-numeric values in the `BMI` column with NaN\n",
    "df['BMI'] = pd.to_numeric(df['BMI'], errors='coerce')   # invalid parsing will be set as NaN with errors='coerce'\n",
    "\n",
    "# Replace the value 999.00 with NaN in the `BMI` column\n",
    "df['BMI'] = df['BMI'].replace(999.00, float('nan'))\n",
    "\n",
    "# Cast the `BMI` column to float\n",
    "df['BMI'] = df['BMI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `TEMPF` column are:\n",
      "['Blank']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `TEMPF` column\n",
    "print('The values of those including non-numeric values in the `TEMPF` column are:')\n",
    "print(df.loc[df['TEMPF'].astype(str).str.contains(r'[^\\d.]'), 'TEMPF'].unique())\n",
    "\n",
    "# Replace 'Blank' with NaN in the `TEMPF` column\n",
    "df['TEMPF'] = df['TEMPF'].replace('Blank', float('nan'))\n",
    "\n",
    "# Cast the `TEMPF` column to float\n",
    "df['TEMPF'] = df['TEMPF'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `BPSYS` column are:\n",
      "['Blank']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `BPSYS` column\n",
    "print('The values of those including non-numeric values in the `BPSYS` column are:')\n",
    "print(df.loc[df['BPSYS'].astype(str).str.contains(r'[^\\d.]'), 'BPSYS'].unique())\n",
    "\n",
    "# Replace 'Blank' with NaN in the `BPSYS` column\n",
    "df['BPSYS'] = df['BPSYS'].replace('Blank', float('nan'))\n",
    "\n",
    "# Cast the `BPSYS` column to float\n",
    "df['BPSYS'] = df['BPSYS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `BPDIAS` column are:\n",
      "['Blank' 'P, PALP, DOPP or DOPPLER']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `BPDIAS` column\n",
    "print('The values of those including non-numeric values in the `BPDIAS` column are:')\n",
    "print(df.loc[df['BPDIAS'].astype(str).str.contains(r'[^\\d.]'), 'BPDIAS'].unique())\n",
    "\n",
    "# Replace 'Blank' with NaN in the `BPDIAS` column\n",
    "df['BPDIAS'] = df['BPDIAS'].replace('Blank', float('nan'))\n",
    "\n",
    "# !!! Replace 'P, PALP, DOPP or DOPPLER' with NaN in the `BPDIAS` column\n",
    "df['BPDIAS'] = df['BPDIAS'].replace('P, PALP, DOPP or DOPPLER', float('nan'))\n",
    "\n",
    "# Cast the `BPDIAS` column to float\n",
    "df['BPDIAS'] = df['BPDIAS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of those including non-numeric values in the `TOTCHRON` column are:\n",
      "['Entire item blank']\n"
     ]
    }
   ],
   "source": [
    "# Check the values of those including non-numeric values in the `TOTCHRON` column\n",
    "print('The values of those including non-numeric values in the `TOTCHRON` column are:')\n",
    "print(df.loc[df['TOTCHRON'].astype(str).str.contains(r'[^\\d.]'), 'TOTCHRON'].unique())\n",
    "\n",
    "# Replace 'Entire item blank' with NaN in the `TOTCHRON` column\n",
    "df['TOTCHRON'] = df['TOTCHRON'].replace('Entire item blank', float('nan'))\n",
    "\n",
    "# Cast the `TOTCHRON` column to float\n",
    "df['TOTCHRON'] = df['TOTCHRON'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value counts of `CASTAGE` are:\n",
      "CASTAGE\n",
      "Not applicable      129162\n",
      "Unknown               3274\n",
      "Unknown stage         1626\n",
      "Local                 1392\n",
      "In situ                693\n",
      "Distant                668\n",
      "Regional               625\n",
      "Stage IV               247\n",
      "Stage III              151\n",
      "Stage II               140\n",
      "Stage 1                128\n",
      "No box is marked        98\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The value counts of `CASTAGE` are:\n",
      "CASTAGE\n",
      "Local        1392\n",
      "In situ       693\n",
      "Distant       668\n",
      "Regional      625\n",
      "Stage IV      247\n",
      "Stage III     151\n",
      "Stage II      140\n",
      "Stage 1       128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the value counts of `CASTAGE`\n",
    "print('The value counts of `CASTAGE` are:')\n",
    "print(df['CASTAGE'].value_counts())\n",
    "\n",
    "# Replace the value 'Not applicable', 'Unknown', 'Unknown stage', and 'No box is marked' with None in the `CASTAGE` column\n",
    "df['CASTAGE'] = df['CASTAGE'].replace('Not applicable', None)\n",
    "df['CASTAGE'] = df['CASTAGE'].replace('Unknown', None)\n",
    "df['CASTAGE'] = df['CASTAGE'].replace('Unknown stage', None)\n",
    "df['CASTAGE'] = df['CASTAGE'].replace('No box is marked', None)\n",
    "\n",
    "# Check the value counts of `CASTAGE`\n",
    "print()\n",
    "print('The value counts of `CASTAGE` are:')\n",
    "print(df['CASTAGE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns that contain `Unknown` or `Blank` values are:\n",
      "Index(['ETHNIC', 'RACE', 'USETOBAC', 'PAYTYPER', 'INJDET', 'MAJOR', 'RFV1',\n",
      "       'RFV2', 'RFV3', 'DIAG1', 'DIAG2', 'DIAG3', 'DMP', 'PROC1', 'PROC2',\n",
      "       'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9', 'NCMED1',\n",
      "       'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean up the other columns which may have 'Unknown' or 'Blank' values\n",
    "\n",
    "# Check the columns that contain 'Unknown' or 'Blank' values\n",
    "unknown_blank_cols = df.columns[df.isin(['Unknown', 'Blank']).any()]\n",
    "\n",
    "# Print the columns that contain 'Unknown' or 'Blank' values\n",
    "print('The columns that contain `Unknown` or `Blank` values are:')\n",
    "print(unknown_blank_cols)\n",
    "\n",
    "# Replace 'Unknown' and 'Blank' with None in the columns that contain 'Unknown' or 'Blank' values\n",
    "df[unknown_blank_cols] = df[unknown_blank_cols].replace(['Unknown', 'Blank'], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Split and save the cleaned OPD DataFrame to a CSV file in '..data/cleaned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and proportion of the data in each set are:\n",
      "\n",
      "Training Data (2006-2008): 103486 rows, approximately 50.7% of the total\n",
      "Validation Data (2009): 33551 rows, approximately 16.4% of the total\n",
      "Test Data (2010): 34718 rows, approximately 17.0% of the total\n",
      "\n",
      "Final Evaluation Data (2011): 32233 rows, approximately 15.8% of the total\n"
     ]
    }
   ],
   "source": [
    "# Hold aside the 2011 data for final evaluation on the model\n",
    "# of the generalizability and adaptability to potential shifts in data over time\n",
    "df_2011 = df[df['file'].str.contains('2011')]\n",
    "\n",
    "# Set the 2010 data as the test set\n",
    "test_df = df[df['file'].str.contains('2010')]\n",
    "\n",
    "# Set the 2009 data as the validation set\n",
    "val_df = df[df['file'].str.contains('2009')]\n",
    "\n",
    "# Set the 2006, 2007, and 2008 data as the training set\n",
    "train_df = df[df['file'].str.contains('2006') | df['file'].str.contains('2007') | df['file'].str.contains('2008')]\n",
    "\n",
    "# Check the number of rows and proportion of the data in each set\n",
    "print('The number of rows and proportion of the data in each set are:')\n",
    "print()\n",
    "print(f'Training Data (2006-2008): {train_df.shape[0]} rows, approximately {train_df.shape[0] / df.shape[0]:.1%} of the total')\n",
    "print(f'Validation Data (2009): {val_df.shape[0]} rows, approximately {val_df.shape[0] / df.shape[0]:.1%} of the total')\n",
    "print(f'Test Data (2010): {test_df.shape[0]} rows, approximately {test_df.shape[0] / df.shape[0]:.1%} of the total')\n",
    "print()\n",
    "print(f'Final Evaluation Data (2011): {df_2011.shape[0]} rows, approximately {df_2011.shape[0] / df.shape[0]:.1%} of the total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned data to CSV files\n",
    "save_path = os.path.join('..', 'data', 'cleaned')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "train_df.to_csv(os.path.join(save_path, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_path, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_path, 'test.csv'), index=False)\n",
    "df_2011.to_csv(os.path.join(save_path, 'final_evaluation.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
