{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression  # Using Logistic instead of Lasso for classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>VMONTH</th>\n",
       "      <th>VYEAR</th>\n",
       "      <th>VDAYR</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ETHNIC</th>\n",
       "      <th>RACE</th>\n",
       "      <th>USETOBAC</th>\n",
       "      <th>...</th>\n",
       "      <th>PHYSASST</th>\n",
       "      <th>NPNMW</th>\n",
       "      <th>RNLPN</th>\n",
       "      <th>OTHPROV</th>\n",
       "      <th>MHP</th>\n",
       "      <th>NODISP</th>\n",
       "      <th>REFOTHMD</th>\n",
       "      <th>RETAPPT</th>\n",
       "      <th>OTHDISP</th>\n",
       "      <th>ERADMHOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opd2006.csv</td>\n",
       "      <td>December</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>White Only</td>\n",
       "      <td>Not current</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One or more dispositions marked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opd2006.csv</td>\n",
       "      <td>November</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>White Only</td>\n",
       "      <td>Not current</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One or more dispositions marked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opd2006.csv</td>\n",
       "      <td>November</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>White Only</td>\n",
       "      <td>Not current</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One or more dispositions marked</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opd2006.csv</td>\n",
       "      <td>November</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>White Only</td>\n",
       "      <td>Not current</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One or more dispositions marked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>opd2006.csv</td>\n",
       "      <td>November</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>White Only</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One or more dispositions marked</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file    VMONTH   VYEAR      VDAYR    YEAR   AGE     SEX  \\\n",
       "0  opd2006.csv  December  2006.0     Friday  2006.0  55.0    Male   \n",
       "1  opd2006.csv  November  2006.0   Thursday  2006.0  66.0    Male   \n",
       "2  opd2006.csv  November  2006.0  Wednesday  2006.0  71.0  Female   \n",
       "3  opd2006.csv  November  2006.0    Tuesday  2006.0   1.0  Female   \n",
       "4  opd2006.csv  November  2006.0     Monday  2006.0  21.0  Female   \n",
       "\n",
       "                   ETHNIC        RACE     USETOBAC  ... PHYSASST NPNMW RNLPN  \\\n",
       "0  Not Hispanic or Latino  White Only  Not current  ...       No    No    No   \n",
       "1  Not Hispanic or Latino  White Only  Not current  ...       No    No    No   \n",
       "2  Not Hispanic or Latino  White Only  Not current  ...       No    No    No   \n",
       "3  Not Hispanic or Latino  White Only  Not current  ...       No    No    No   \n",
       "4  Not Hispanic or Latino  White Only      Current  ...       No    No    No   \n",
       "\n",
       "  OTHPROV  MHP                           NODISP REFOTHMD RETAPPT OTHDISP  \\\n",
       "0      No  NaN  One or more dispositions marked       No      No      No   \n",
       "1      No  NaN  One or more dispositions marked       No      No      No   \n",
       "2      No  NaN  One or more dispositions marked      Yes      No      No   \n",
       "3      No  NaN  One or more dispositions marked       No      No      No   \n",
       "4      No  NaN  One or more dispositions marked       No      No      No   \n",
       "\n",
       "  ERADMHOS  \n",
       "0       No  \n",
       "1       No  \n",
       "2       No  \n",
       "3       No  \n",
       "4       No  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('..', 'data', 'cleaned')\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(file_path, 'train.csv'), low_memory=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load the vairiables dictionary and define features for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Categories:\n",
      "\n",
      "dateOfVisit\n",
      "['VMONTH', 'VYEAR', 'VDAYR', 'YEAR']\n",
      "demographics\n",
      "['AGE', 'SEX', 'ETHNIC', 'RACE', 'USETOBAC']\n",
      "payment\n",
      "['PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPER']\n",
      "visitReason\n",
      "['INJDET', 'INJURY', 'MAJOR', 'RFV1', 'RFV2', 'RFV3']\n",
      "patientClinicHistory\n",
      "['SENBEFOR', 'PASTVIS']\n",
      "vitalSigns\n",
      "['HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS']\n",
      "imputedFields\n",
      "['BDATEFL', 'SEXFL', 'SENBEFL', 'PASTFL']\n",
      "physicianDiagnoses\n",
      "['DIAG1', 'DIAG2', 'DIAG3']\n",
      "differentialDiagnoses\n",
      "['PRDIAG1', 'PRDIAG2', 'PRDIAG3']\n",
      "presentSymptomsStatus\n",
      "['ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'NOCHRON', 'TOTCHRON', 'DMP']\n",
      "services\n",
      "['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9', 'CATSCAN', 'PREGTEST', 'FOOT', 'RETINAL', 'HIVTEST', 'CAST', 'SPLINT']\n",
      "healthEducation\n",
      "['ASTHMAED', 'DIETNUTR', 'EXERCISE', 'GRWTHDEV', 'INJPREV', 'STRESMGT', 'TOBACED', 'WTREDUC', 'OTHLTHED']\n",
      "medicationsAndImmunizations\n",
      "['MED1', 'MED2', 'MED3', 'MED4', 'MED5', 'MED6', 'MED7', 'MED8', 'NCMED1', 'NCMED2', 'NCMED3', 'NCMED4', 'NCMED5', 'NCMED6', 'NCMED7', 'NCMED8', 'NUMNEW', 'NUMCONT']\n",
      "providersSeen\n",
      "['NOPROVID', 'PHYS', 'PHYSASST', 'NPNMW', 'RNLPN', 'OTHPROV', 'MHP']\n",
      "visitDisposition\n",
      "['NODISP', 'REFOTHMD', 'RETAPPT', 'OTHDISP', 'ERADMHOS']\n"
     ]
    }
   ],
   "source": [
    "# Load the variables dictionary\n",
    "with open(os.path.join(file_path, 'variables.json'), 'r') as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "print(f'Variable Categories:\\n')\n",
    "for category, list in variables.items():\n",
    "    print(f'{category}')\n",
    "    print(f'{list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['AGE', 'SEX', 'ETHNIC', 'RACE', 'HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS', 'SENBEFOR', 'PASTVIS', 'ARTHRTIS', 'ASTHMA', 'CANCER', 'CASTAGE', 'CEBVD', 'CHF', 'CRF', 'COPD', 'DEPRN', 'DIABETES', 'HYPLIPID', 'HTN', 'IHD', 'OBESITY', 'OSTPRSIS', 'DMP']\n",
      "Number of Features: 28\n"
     ]
    }
   ],
   "source": [
    "# Defining the independent variables as features\n",
    "features = [item for item in variables['demographics'] if item not in ['USETOBAC']]\\\n",
    "           + variables['vitalSigns']  \\\n",
    "         + variables['patientClinicHistory']\\\n",
    "        + [item for item in variables['presentSymptomsStatus'] if item not in ['NOCHRON', 'TOTCHRON']]\n",
    "#+ variables['healthEducation']+ variables['visitReason']+ variables['vitalSigns']\n",
    "print(f'Features: {features}')\n",
    "print(f'Number of Features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ftargets: ['BREAST', 'PELVIC', 'RECTAL', 'SKIN', 'DEPRESS', 'BONEDENS', 'MAMMO', 'MRI', 'ULTRASND', 'XRAY', 'OTHIMAGE', 'CBC', 'ELECTROL', 'GLUCOSE', 'HGBA', 'CHOLEST', 'PSA', 'OTHERBLD', 'BIOPSY', 'CHLAMYD', 'PAPCONV', 'PAPLIQ', 'PAPUNSP', 'HPVDNA', 'EKG', 'SPIRO', 'URINE', 'HTTAKE', 'WTTAKE', 'TEMPTAKE', 'BLODPRES', 'CAM', 'DME', 'HOMEHLTH', 'HOSPICE', 'PT', 'RADTHER', 'SPOCTHER', 'PSYCHOTH', 'OTHMNTL', 'EXCISION', 'ORTHO', 'WOUND', 'ECHOCARD', 'OTHULTRA', 'PROC1', 'PROC2', 'PROC3', 'PROC4', 'PROC5', 'PROC6', 'PROC7', 'PROC8', 'PROC9', 'CATSCAN', 'PREGTEST', 'FOOT', 'RETINAL', 'HIVTEST', 'CAST', 'SPLINT']\n",
      "Number of Ftargets: 61\n"
     ]
    }
   ],
   "source": [
    "targets = variables['services']\n",
    "        #+ variables['differentialDiagnoses']  + variables['physicianDiagnoses'] \n",
    "print(f'Ftargets: {targets}')\n",
    "print(f'Number of Ftargets: {len(targets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65377"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['BMI'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317472894884332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65377/103486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of the 'BMI' column\n",
    "bmi_median = train_df['BMI'].median()\n",
    "\n",
    "# Fill NaN values in the 'BMI' column with the calculated median\n",
    "train_df['BMI'] = train_df['BMI'].fillna(bmi_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "numeric_features = ['AGE', 'HTIN', 'WTLB', 'BMI', 'TEMPF', 'BPSYS', 'BPDIAS','PASTVIS']\n",
    "categorical_features = sorted(set(features)- set(numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count in AGE: 0\n",
      "NaN count in HTIN: 0\n",
      "NaN count in WTLB: 0\n",
      "NaN count in BMI: 0\n",
      "NaN count in TEMPF: 0\n",
      "NaN count in BPSYS: 0\n",
      "NaN count in BPDIAS: 0\n",
      "NaN count in PASTVIS: 0\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the list of numeric features\n",
    "for column in numeric_features:\n",
    "    # Calculate the median of each column\n",
    "    median_value = train_df[column].median()\n",
    "    \n",
    "    # Fill NaN values in each column with its calculated median\n",
    "    train_df[column] = train_df[column].fillna(median_value)\n",
    "\n",
    "# Optionally, check if there are any NaN values left in the numeric features\n",
    "for column in numeric_features:\n",
    "    print(f\"NaN count in {column}: {train_df[column].isna().sum()}\")  # This should print 0 for each column if all NaN values are filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count in ARTHRTIS: 0\n",
      "NaN count in ASTHMA: 0\n",
      "NaN count in CANCER: 0\n",
      "NaN count in CASTAGE: 0\n",
      "NaN count in CEBVD: 0\n",
      "NaN count in CHF: 0\n",
      "NaN count in COPD: 0\n",
      "NaN count in CRF: 0\n",
      "NaN count in DEPRN: 0\n",
      "NaN count in DIABETES: 0\n",
      "NaN count in DMP: 0\n",
      "NaN count in ETHNIC: 0\n",
      "NaN count in HTN: 0\n",
      "NaN count in HYPLIPID: 0\n",
      "NaN count in IHD: 0\n",
      "NaN count in OBESITY: 0\n",
      "NaN count in OSTPRSIS: 0\n",
      "NaN count in RACE: 0\n",
      "NaN count in SENBEFOR: 0\n",
      "NaN count in SEX: 0\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the list of categorical features\n",
    "for column in categorical_features:\n",
    "    # Fill NaN values in each column with 'unknown'\n",
    "    train_df[column] = train_df[column].fillna('unknown')\n",
    "\n",
    "# Optionally, check if there are any NaN values left in the categorical features\n",
    "for column in categorical_features:\n",
    "    print(f\"NaN count in {column}: {train_df[column].isna().sum()}\")  # This should print 0 for each column if all NaN values are filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df[targets]\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/087lbgr93bz26h0_1_0lfyxw0000gn/T/ipykernel_37306/3094077582.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  y_train[column].fillna('unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Adjust y_train imputation strategy\n",
    "# If y_train is a DataFrame with multiple target columns, impute each column\n",
    "for column in y_train.columns:\n",
    "    y_train[column].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lai/Library/Mobile Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                            (\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m, wrapped_model)])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#print(X_train.sample(5))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#print(y_train.sample(5))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lai/Library/Mobile%20Documents/com~apple~CloudDocs/UM/699_Capstone/Project/pathclarity/notebooks/3.2-jy-xt-ModelComparsion.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy_score(y_test,\u001b[39m \u001b[39mpreds)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/multioutput.py:538\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    513\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \n\u001b[1;32m    515\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[1;32m    540\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/multioutput.py:273\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         routed_params\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mfit[\u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sample_weight\n\u001b[0;32m--> 273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    274\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    275\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mfit\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    278\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    281\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MultiOutput Wrapper\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(next(iter(models.keys())))\n",
    "    wrapped_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', wrapped_model)])\n",
    "    #print(X_train.sample(5))\n",
    "    #print(y_train.sample(5))\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
